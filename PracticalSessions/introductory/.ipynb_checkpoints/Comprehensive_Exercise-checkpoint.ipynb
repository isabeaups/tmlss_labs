{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYx6oEVKcE_L"
   },
   "source": [
    "# Exercise: putting everything together\n",
    "\n",
    "\n",
    "In this you will write code for a model that learns to classify mnist digits. You will use sonnet and tensorflow, tracking training progress with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TGBJLkR_cI3L"
   },
   "outputs": [],
   "source": [
    "# Install dm-sonnet with pip. Include all necessary imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5gkBQpjJlCgP"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nO_tMPdncmVy"
   },
   "outputs": [],
   "source": [
    "# Fetch the mnist data from tf.keras.datasets.mnist.\n",
    "\n",
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Check what the data is like:\n",
    "print('Training dataset:')\n",
    "train_input, train_label = mnist_train\n",
    "print('* input shape:', train_input.shape)\n",
    "print('* input min, mean, max:', train_input.min(), train_input.mean(), train_input.max())\n",
    "print('* input dtype:', train_input.dtype)\n",
    "print('* label shape:', train_label.shape)\n",
    "print('* label min, mean, max:', train_label.min(), train_label.mean(), train_label.max())\n",
    "print('* label dtype:', train_label.dtype)\n",
    "\n",
    "test_input, test_label = mnist_test\n",
    "print('Number of test examples:', test_input.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utL4ZmLrepoH"
   },
   "source": [
    "Normalize the data into the \\[0, 1\\] interval. It's also a good idea to check the class distribution, but here we know that this is OK.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "60_4wXEPe7Ig"
   },
   "outputs": [],
   "source": [
    "# Normalize both train_input and test_input so that it is in [0, 1].\n",
    "#\n",
    "# Also ensure the following data types:\n",
    "#\n",
    "# * train_input and test_input need to be np.float32.\n",
    "# * the labels need to be converted to np.int32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JDwRkDiYfzVO"
   },
   "outputs": [],
   "source": [
    "# We can visualize the first few training examples using matplotlib.imshow()\n",
    "# in combination with the gallery function we defined.\n",
    "#\n",
    "# Copy the gallery function in this cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1WQD1huVgV8Y"
   },
   "outputs": [],
   "source": [
    "# Show the first 6 training images on a 1x6 grid.\n",
    "# Remember to use grayscale plotting.\n",
    "# Also print their corresponding labels in the same order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6VZdwYo_fUpo"
   },
   "outputs": [],
   "source": [
    "# Write a function that turns the data into tensorflow datasets and into\n",
    "# tensors corresponding to batches of examples, returning these tensors.\n",
    "#\n",
    "# The train data should be\n",
    "#\n",
    "# * shuffled across the full dataset\n",
    "# * repeated indefinitely\n",
    "# * batched at size 64.\n",
    "#\n",
    "# Simply batch the test data.\n",
    "#\n",
    "# IMPORTANT: Add a final (singleton) axis to the inputs; the conv nets that\n",
    "# we will use will expect this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "d3JcANwNfHuQ"
   },
   "outputs": [],
   "source": [
    "# Make a sonnet module that has the following structure:\n",
    "#\n",
    "# 1. sonnet Conv2D with 16 channes, kernel shape 3, stride 1, padding 'SAME'\n",
    "# 2. max pooling with window_shape [3, 3], srides [2, 2], padding 'SAME'\n",
    "# 3. ReLU\n",
    "# 4. sonnet Conv2D with 16 channes, kernel shape 3, stride 1, padding 'SAME'\n",
    "# 5. Flatten the final conv features using snt.BatchFlatten\n",
    "# 5. A (dense) Linear layer with output_size = 10, the number of classes.\n",
    "#\n",
    "# You can write the sonnet module yourself, or use the helper module\n",
    "# snt.Sequential([..layers..to..connect..]).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YRp2hrGofH7f"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "(train_inputs, train_labels), (test_inputs, test_labels) = get_tf_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "g7daVkyoqS9p"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiate a model\n",
    "# 2. Hook it up to the training data,\n",
    "# 3. Use the `tf.nn.sparse_softmax_cross_entropy_with_logits` op to define the loss\n",
    "# 4. Define the train_op that minimizes the loss (averaged over the batch)\n",
    "#    using the `GradientDescentOptimizer`. Set the learning rate to 0.01.\n",
    "# 5. Get the initialization op.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Wvmlucn6vbSD"
   },
   "outputs": [],
   "source": [
    "# Write a function that takes a list of losses and plots them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tufk2Xa2qTEI"
   },
   "outputs": [],
   "source": [
    "# Run the training loop, keeping track of losses and potentially the accuracy\n",
    "# on the training set. Plot the loss curve intermittently.\n",
    "#\n",
    "# The simplest solution would add a new plot with each plotting call. You\n",
    "# can play with the frequency of plotting (and recording) a bit in order\n",
    "# to find something that works.\n",
    "#\n",
    "# Based on the loss curves, decide how to set your total number of training\n",
    "# iterations. Once you are satified, add some code that evaluates your\n",
    "# prediction accuracy (not loss!) on the test set.\n",
    "#\n",
    "# Note that the outputs from the network are logits; for prediction accuracy\n",
    "# we can pick the most likely label and see if it is correct.\n",
    "\n",
    "# The accuracy you should expect:\n",
    "#\n",
    "# * Roughly 90% after 1000 training steps.\n",
    "# * 97-98% after 10k training steps.\n",
    "#\n",
    "# First iterate with 1k steps, if that works, train for 10k. 10k steps will\n",
    "# be roughly 6 minutes on CPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0fwSrI-c2Cn3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Xvt4bOeP1Bbo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ChrJA2KOqTMD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Comprehensive Exercise.ipynb",
   "provenance": [
    {
     "file_id": "1r4IWzK2gHwXnbumu-1avZ9flg8ixREaM",
     "timestamp": 1530768533770
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
