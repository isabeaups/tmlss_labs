{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mobilenet_start.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1esQQVikNcpGigtgmVF-QP6p47Ikra-23","timestamp":1531831731455},{"file_id":"/v2/external/notebooks/welcome.ipynb","timestamp":1529240593757}],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"9J7p406abzgl","colab_type":"text"},"cell_type":"markdown","source":["## Part IV:  [Mobilenet](https://arxiv.org/pdf/1704.04861.pdf) separable convolutions\n","- modify the model in part I to use *separable* convolutions\n","- check number of parameters and compare with the previous model\n","- train classifier\n","\n","Architecture (same as in part I):\n","- conv output channels 64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n","- kernel shape (3,3)\n","- strides: 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1\n","- padding: SAME (snt.SAME)\n","- num_output_classes = 10\n"]},{"metadata":{"id":"FhWI4Pix5GJw","colab_type":"text"},"cell_type":"markdown","source":["### Imports"]},{"metadata":{"id":"na0VvPXmYKp1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":723},"outputId":"bdad9355-ceb1-4f5c-934c-a2783c6f14cf","executionInfo":{"status":"error","timestamp":1531840928194,"user_tz":-180,"elapsed":3181,"user":{"displayName":"Isabeau PrÃ©mont-Schwarz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117345478751037073212"}}},"cell_type":"code","source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import math\n","import time\n","\n","import tensorflow as tf\n","\n","# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","# we will use Sonnet on top of TF \n","!pip install -q dm-sonnet\n","import sonnet as snt\n","\n","import numpy as np\n","\n","# Plotting library.\n","from matplotlib import pyplot as plt\n","import pylab as pl\n","from IPython import display"],"execution_count":1,"outputs":[{"output_type":"error","ename":"InternalError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-1-805691df51be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/test_util.pyc\u001b[0m in \u001b[0;36mgpu_device_name\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;34m\"\"\"Returns the name of a GPU device if available or the empty string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SYCL\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/device_lib.pyc\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m     39\u001b[0m   return [\n\u001b[1;32m     40\u001b[0m       \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   ]\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.pyc\u001b[0m in \u001b[0;36mlist_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m   1684\u001b[0m                                           status)\n\u001b[1;32m   1685\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1686\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mListDevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY; total memory reported: 11995578368"]}]},{"metadata":{"id":"1xlKHOLbhvY7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Reset graph\n","tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8g16XweXs2Uq","colab_type":"text"},"cell_type":"markdown","source":["### Download dataset to be used for training and testing\n","- Cifar-10 equivalent of MNIST for natural RGB images\n","- 60000 32x32 colour images in 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n","- train: 50000; test: 10000"]},{"metadata":{"id":"1g_EOx07s1XZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["cifar10 = tf.keras.datasets.cifar10\n","# (down)load dataset\n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rt6hU4aQtwpZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":153},"cellView":"form","outputId":"5a799c79-1b62-48c9-e75e-286947ad0a94","executionInfo":{"status":"ok","timestamp":1531831780156,"user_tz":-60,"elapsed":844,"user":{"displayName":"Diana Borsa","photoUrl":"//lh3.googleusercontent.com/-ncAFLYhkpa4/AAAAAAAAAAI/AAAAAAAABCo/oObvci_cgWA/s50-c-k-no/photo.jpg","userId":"113702420363391077417"}}},"cell_type":"code","source":["#@title (optional) Check sizes of tensors\n","print ('Size of training images')\n","print (train_images.shape)\n","print ('Size of training labels')\n","print (train_labels.shape)\n","print ('Size of test images')\n","print (test_images.shape)\n","print ('Size of test labels')\n","print (test_labels.shape)\n","\n","assert train_images.shape[0] == train_labels.shape[0]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Size of training images\n","(50000, 32, 32, 3)\n","Size of training labels\n","(50000, 1)\n","Size of test images\n","(10000, 32, 32, 3)\n","Size of test labels\n","(10000, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"JHAggitWu94_","colab_type":"text"},"cell_type":"markdown","source":["### Prepare the data for training and testing\n","- for training, we use stochastic optimizers (e.g. SGD, Adam), so we need to sample at random mini-batches from the training dataset\n","- for testing, we iterate sequentially through the test set"]},{"metadata":{"id":"iZofMjOuUEOF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["# define dimension of the batches to sample from the datasets\n","BATCH_SIZE_TRAIN = 128 #@param\n","BATCH_SIZE_TEST = 100 #@param\n","\n","# create Dataset objects using the data previously downloaded\n","dataset_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n","# we shuffle the data and sample repeatedly batches for training\n","batched_dataset_train = dataset_train.shuffle(100000).repeat().batch(BATCH_SIZE_TRAIN)\n","# create iterator to retrieve batches\n","iterator_train = batched_dataset_train.make_one_shot_iterator()\n","# get a training batch of images and labels\n","(batch_train_images, batch_train_labels) = iterator_train.get_next()\n","\n","# check that the shape of the training batches is the expected one\n","# print ('Shape of training images')\n","# print (batch_train_images)\n","# print ('Shape of training labels')\n","# print (batch_train_labels)\n","\n","# we do the same for test dataset\n","dataset_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n","batched_dataset_test = dataset_test.repeat().batch(BATCH_SIZE_TEST)\n","iterator_test = batched_dataset_test.make_one_shot_iterator() \n","(batch_test_images, batch_test_labels) = iterator_test.get_next()\n","# print ('Shape of test images')\n","# print (batch_test_images)\n","# print ('Shape of test labels')\n","# print (batch_test_labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_PS2GjTxRZx9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title Preprocessing of data\n","# preprocess input for training and testing\n","def random_flip_left_right(image, flip_index, seed=None):\n","  shape = image.get_shape()\n","  if shape.ndims == 3 or shape.ndims is None:\n","    uniform_random = tf.random_uniform([], 0, 1.0, seed=seed)\n","    mirror_cond = tf.less(uniform_random, .5)\n","    result = tf.cond(\n","        mirror_cond,\n","        lambda: tf.reverse(image, [flip_index]),\n","        lambda: image\n","    )\n","    return fix_image_flip_shape(image, result)\n","  elif shape.ndims == 4:\n","    uniform_random = tf.random_uniform(\n","        [tf.shape(image)[0]], 0, 1.0, seed=seed\n","    )\n","    mirror_cond = tf.less(uniform_random, .5)\n","    return tf.where(\n","        mirror_cond,\n","        image,\n","        tf.map_fn(lambda x: tf.reverse(x, [flip_index]), image, dtype=image.dtype)\n","    )\n","  else:\n","    raise ValueError(\"\\'image\\' must have either 3 or 4 dimensions.\")\n","    \n","def train_image_preprocess(h, w, random_flip=True):\n","  \"\"\"Image processing required for training the model.\"\"\"\n","\n","  def fn(image):\n","    batch_size = image.get_shape().as_list()[0]\n","    # Ensure the data is in range [-1, 1].\n","    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n","    image = image * 2.0 - 1.0\n","    # Randomly choose a (24, 24, 3) patch to be used for training.\n","    image = tf.random_crop(image, size=(BATCH_SIZE_TRAIN, h, w, 3))\n","    # Randomly flip the image.\n","    image = random_flip_left_right(image, 2)\n","    return image\n","\n","  return fn\n","\n","def test_image_preprocess():\n","  def fn(image):\n","    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n","    image = image * 2.0 - 1.0\n","    return image\n","  return fn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jnsUw-N6lMng","colab_type":"text"},"cell_type":"markdown","source":["### Separable convolutions\n","\n","For example, a 2D conv can be written as a sequence of 2 1D conv, i.e. \\begin{equation} y[m,n]=x[m,n]*h[m,n] = h_1[m]*(h_2[n]*x[m,n])\\end{equation}\n","\n","assuming $x$ is a 2D input signal, $h$ is a 2D filter that can be separated into 2 1D filters $h_1$ and $h_2$, and $y$ is the output of convolving $x$ with $h$.  \n","\n","\n","Similarly for 3D case, we apply the separability between feature channel and spatial dimensions (as shown in the figure below on the left), i.e. \\begin{equation} y[m,n,p]=x[m,n, p]*h[m,n,p] = h_1[p]*(h_2[m,n]*x[m,n,p])\\end{equation}\n","\n","![alt text](https://tmlss.ro/lab_tmp/separable.png)"]},{"metadata":{"id":"oAn3iRDvlXEa","colab_type":"text"},"cell_type":"markdown","source":["### Modify the previous classifier to use *separable* convolutions; the first conv unit stays the same."]},{"metadata":{"id":"YW52gs-gldhY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class Mobilenet(snt.AbstractModule):\n","  \n","  def __init__(self, num_classes, name=\"mobilenet\"):\n","    super(Mobilenet, self).__init__(name=name)\n","    self._num_classes = num_classes\n","    self._channel_multipliers = [\n","        0, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1\n","    ]\n","    self._output_channels = [\n","        64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n","    ]\n","    self._num_layers = len(self._output_channels)\n","\n","    self._kernel_shapes = [[3, 3]] * self._num_layers  # All kernels are 3x3.\n","    self._strides = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n","    self._paddings = [snt.SAME] * self._num_layers\n","   \n","  def _build(self, inputs, is_training=None, test_local_stats=False):\n","    net = inputs\n","    # instantiate all the convolutional layers\n","    \n","    # instantiate depthwise conv layers\n","    \n","    # instantiate 1x1 conv layers\n","    \n","    # construct network    \n","\n","    net = tf.reduce_mean(net, reduction_indices=[1, 2], keepdims=False,\n","                         name=\"avg_pool\")\n","\n","    logits = snt.Linear(self._num_classes)(net)\n","\n","    return logits"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z4F6qR1OT0oj","colab_type":"text"},"cell_type":"markdown","source":["## Parameter Comparison\n","\n","What are the number of the parameters of this new model. How does it compare with the number computed for the baseline?"]},{"metadata":{"id":"OD8IR90m_0-r","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"both"},"cell_type":"code","source":["#@title Function to compute nr of params\n","\n","def get_num_params(scope):\n","  total_parameters = 0\n","  for variable in tf.trainable_variables(scope):\n","    # shape is an array of tf.Dimension\n","    shape = variable.get_shape()\n","    variable_parameters = 1\n","    for dim in shape:\n","      variable_parameters *= dim.value\n","    total_parameters += variable_parameters\n","  return total_parameters\n","\n","#get_num_params('mobilenet')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"inX9OlHW5xWR","colab_type":"text"},"cell_type":"markdown","source":["### Connect the model to the data \n"]},{"metadata":{"id":"TZzlpO0oJFZy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# First define the preprocessing ops for the train/test data\n","crop_height = 24 #@param\n","cropt_width = 24 #@param\n","preprocess_fn_train = train_image_preprocess(crop_height, cropt_width)\n","preprocess_fn_test = test_image_preprocess()\n","\n","num_classes = 10 #@param"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5K4VMXej8Fem","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# for evaluation, we look at top_k_accuracy since it's easier to interpret; normally k=1 or k=5\n","def top_k_accuracy(k, labels, logits):\n","  in_top_k = tf.nn.in_top_k(predictions=tf.squeeze(logits), targets=tf.squeeze(tf.cast(labels, tf.int32)), k=k)\n","  return tf.reduce_mean(tf.cast(in_top_k, tf.float32))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G_6cvqi_nuZ9","colab_type":"text"},"cell_type":"markdown","source":["### Instantiate Mobilenet, get number of parameters and compare with baseline"]},{"metadata":{"id":"a86sl1lLmOVc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"8a0ae2e5-5b27-40b9-9866-a8e2834ff72e","executionInfo":{"status":"ok","timestamp":1531831795081,"user_tz":-60,"elapsed":1926,"user":{"displayName":"Diana Borsa","photoUrl":"//lh3.googleusercontent.com/-ncAFLYhkpa4/AAAAAAAAAAI/AAAAAAAABCo/oObvci_cgWA/s50-c-k-no/photo.jpg","userId":"113702420363391077417"}}},"cell_type":"code","source":["with tf.variable_scope(\"mobilenet_model\"):\n","  mobilenet = Mobilenet(num_classes=10)\n","\n","predictions_mobilenet = mobilenet(preprocess_fn_train(batch_train_images), is_training=True)\n","print (predictions_mobilenet)\n","test_predictions_mobilenet = mobilenet(preprocess_fn_test(batch_test_images), is_training=False)\n","print (test_predictions_mobilenet)\n","  \n","print ('Number of parameters of Mobilenet is')\n","print (get_num_params(\"mobilenet_model\"))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tensor(\"mobilenet/linear/add:0\", shape=(128, 10), dtype=float32)\n","Tensor(\"mobilenet_1/linear/add:0\", shape=(?, 10), dtype=float32)\n","Number of parameters of Mobilenet is\n","1079050\n"],"name":"stdout"}]},{"metadata":{"id":"lGyLJwJ408ZZ","colab_type":"text"},"cell_type":"markdown","source":["### Create the optimizer: SGD with momentum"]},{"metadata":{"id":"f8V7fy_U2yY2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_optimizer(step):\n","  \"\"\"Get the optimizer used for training.\"\"\"\n","  lr_schedule = (40e3, 60e3, 80e3)\n","  lr_schedule = tf.to_int64(lr_schedule)\n","  lr_factor = 0.1\n","  \n","  lr_init = 0.1\n","  num_epochs = tf.reduce_sum(tf.to_float(step >= lr_schedule))\n","  lr = lr_init * lr_factor**num_epochs\n","\n","  return tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eO1xIgRtjvXU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["MAX_IMAGES = 10\n","def gallery(seq, lbl, class_dict, title='Display input'):\n","  num_frames, h, w, num_channels = seq.shape\n","  num_frames = min(num_frames, MAX_IMAGES)\n","  ff, axes = plt.subplots(1, num_frames,\n","                          figsize=(num_frames, 1),\n","                          subplot_kw={'xticks': [], 'yticks': []})\n","  for i in range(0, num_frames):\n","    if num_channels == 3:\n","      axes[i].imshow(np.squeeze(seq[i]))\n","    else:\n","      axes[i].imshow(np.squeeze(seq[i]), cmap='gray')\n","    axes[i].set_title(class_dict[lbl[i][0]])\n","    plt.setp(axes[i].get_xticklabels(), visible=False)\n","    plt.setp(axes[i].get_yticklabels(), visible=False)\n","  ff.subplots_adjust(wspace=0.1)\n","  plt.show()\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"PTFLYiWv8Z_n","colab_type":"text"},"cell_type":"markdown","source":["### Set up the training"]},{"metadata":{"id":"s-m8-e5vpUIQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Define number of training iterations and reporting intervals\n","TRAIN_ITERS = 90e3 #@param\n","REPORT_TRAIN_EVERY = 100 #@param\n","PLOT_EVERY = 500 #@param\n","REPORT_TEST_EVERY = 1000 #@param\n","TEST_ITERS = 10 #@param\n","lr_init = 0.1 #@param\n","display_inputs = False #@param\n","\n","class_mapping = [u'airplane', u'automobile', u'bird', u'cat', u'deer', u'dog', u'frog', u'horse', u'ship', u'truck']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pF0oEXrHFB7W","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Write a function that takes a list of losses and plots them.\n","def plot_losses(loss_list, steps):\n","  display.clear_output(wait=True)\n","  display.display(pl.gcf())\n","  pl.plot(steps, loss_list)\n","  time.sleep(1.0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mKOKrcm07DWW","colab_type":"text"},"cell_type":"markdown","source":["### Training MobileNet\n"]},{"metadata":{"id":"7lTGliNcnIfE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# define train and test loss functions\n","\n","# Create a global step that is incremented during training; useful for e.g. learning rate annealing\n","global_step = tf.train.get_or_create_global_step()\n","\n","# instantiate the optimizer\n","optimizer, lr_op = get_optimizer(global_step)\n","\n","# Get training and test ops\n","# training_op = \n","# update_ops = \n","# training_op = tf.group(training_op, update_ops)\n","\n","test_acc_op = top_k_accuracy(1, batch_test_labels, test_predictions_mobilenet)\n","\n","# Create the session and initialize variables\n","sess = tf.Session()\n","sess.run(tf.initialize_all_variables())\n","\n","# run training; at every k iterations, run evaluation too\n","train_iter = 0\n","display_inputs = False\n","losses = []\n","steps = []\n","for train_iter in range(int(TRAIN_ITERS)):\n","  _, train_loss, lr, img_inp, lbl_inp = sess.run([training_op, train_loss_op, lr_op, batch_train_images, batch_train_labels])\n","  \n","  if (train_iter % REPORT_TRAIN_EVERY) == 0:\n","    print ('Train loss at iter {0:5d} out of {1:5d} is {2:.2f}'.format(int(train_iter), int(TRAIN_ITERS), train_loss)) \n","    \n","  if (train_iter % REPORT_TEST_EVERY) == 0:\n","    avg_acc = 0.0\n","    for test_iter in range(TEST_ITERS):\n","      acc = sess.run(test_acc_op)\n","      avg_acc += acc\n","      \n","    if display_inputs:\n","      gallery(img_inp, lbl_inp, class_mapping)\n","    avg_acc /= (TEST_ITERS)\n","    print ('Test acc at iter {0:5d} out of {1:5d} is {2:.2f}'.format(int(train_iter), int(TRAIN_ITERS), avg_acc*100.0))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9kwj9LLvSl6j","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}