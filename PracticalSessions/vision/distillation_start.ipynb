{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"distillation_start.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"/v2/external/notebooks/welcome.ipynb","timestamp":1529240593757}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"lzkm9_53o1H4","colab_type":"text"},"cell_type":"markdown","source":["## Part III: [Distilling the knowledge](https://arxiv.org/pdf/1503.02531.pdf) from a (larger) teacher model\n","\n","- import an already trained baseline model\n","- add KL distillation loss between teacher and student\n","- train Mobilenet classifier with this joint loss\n"]},{"metadata":{"id":"W5f4X7Zbpat0","colab_type":"text"},"cell_type":"markdown","source":["### Train Mobilenet with distillation loss, we use Kullback-Leibler (KL) divergence \n","\n","Define loss as\n","\\begin{equation}\n","\\mathcal{L} = \\lambda \\mathcal{L}_{\\text{distill}} + \\mathcal{L}_{\\text{classif}}\n","\\end{equation}\n","\n","where\n","\\begin{equation}\n","\\mathcal{L}_{\\text{distill}} = \\text{KL}(\\text{p}_{\\text{teacher}}, \\text{p}_{\\text{student}}).\n","\\end{equation}\n","\n","\n","Recall the definition of\n","$$\\text{KL}(p||q) = \\sum_{i=1}^{N}p(x_i) \\cdot \\log \\frac{p(x_i)}{q(x_i)} . $$\n","\n","The outputs of the networks are logits, which we interpret as probabilities when passed through softmax:\n","\n","$$p_i^{(T)} =\\frac{\\exp{(\\text{logits}_i / T) }}{\\sum_j \\exp{(\\text{logits}_j / T) }} $$\n","\n","where $T$ is a temperature and usually we set it to $1$. Setting it to a higher number smoothens the probability distribution. To be fully precise, we will use\n","\n","\\begin{equation}\n","\\mathcal{L}_{\\text{distill}} = \\text{KL}(\\text{p}_{\\text{teacher}}^{(T)}, \\text{p}_{\\text{student}}^{(T)}),\n","\\end{equation}\n","\n","$$\\lambda = T^2.$$\n","\n","\n","\n"]},{"metadata":{"id":"FhWI4Pix5GJw","colab_type":"text"},"cell_type":"markdown","source":["\n","### Imports"]},{"metadata":{"id":"na0VvPXmYKp1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"e6942411-3201-4ac9-e012-3c52836f291c","executionInfo":{"status":"ok","timestamp":1531840535836,"user_tz":-180,"elapsed":7389,"user":{"displayName":"Isabeau PrÃ©mont-Schwarz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117345478751037073212"}}},"cell_type":"code","source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import math\n","import time\n","\n","import tensorflow as tf\n","\n","# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","# we will use Sonnet on top of TF \n","!pip install -q dm-sonnet\n","import sonnet as snt\n","\n","import numpy as np\n","\n","# Plotting library.\n","from matplotlib import pyplot as plt\n","import pylab as pl\n","from IPython import display"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"1xlKHOLbhvY7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Reset graph\n","tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V5JKC1HMpnmF","colab_type":"text"},"cell_type":"markdown","source":["### Copy the pretrained weights of baseline model on the virtual machine\n","- you need to load all three files in the *baseline_weights* folder"]},{"metadata":{"id":"cubpPmHgECbc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":73},"outputId":"48b08d02-ab51-4ef7-fa5d-e3da97df8e77"},"cell_type":"code","source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-4c1e7b6b-5293-4974-9ff3-141c883c3479\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-4c1e7b6b-5293-4974-9ff3-141c883c3479\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving baseline.ckpt.data-00000-of-00001 to baseline.ckpt (1).data-00000-of-00001\n"],"name":"stdout"}]},{"metadata":{"id":"8g16XweXs2Uq","colab_type":"text"},"cell_type":"markdown","source":["### Download dataset to be used for training and testing\n","- Cifar-10 equivalent of MNIST for natural RGB images\n","- 60000 32x32 colour images in 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n","- train: 50000; test: 10000"]},{"metadata":{"id":"1g_EOx07s1XZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["cifar10 = tf.keras.datasets.cifar10\n","# (down)load dataset\n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JHAggitWu94_","colab_type":"text"},"cell_type":"markdown","source":["### Prepare the data for training and testing\n","- for training, we use stochastic optimizers (e.g. SGD, Adam), so we need to sample at random mini-batches from the training dataset\n","- for testing, we iterate sequentially through the test set"]},{"metadata":{"id":"iZofMjOuUEOF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# define dimension of the batches to sample from the datasets\n","BATCH_SIZE_TRAIN = 64 #@param\n","BATCH_SIZE_TEST = 100 #@param\n","\n","# create Dataset objects using the data previously downloaded\n","dataset_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n","# we shuffle the data and sample repeatedly batches for training\n","batched_dataset_train = dataset_train.shuffle(100000).repeat().batch(BATCH_SIZE_TRAIN)\n","# create iterator to retrieve batches\n","iterator_train = batched_dataset_train.make_one_shot_iterator()\n","# get a training batch of images and labels\n","(batch_train_images, batch_train_labels) = iterator_train.get_next()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yWtdQ0ESxkBQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# we do the same for test dataset\n","dataset_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n","batched_dataset_test = dataset_test.repeat().batch(BATCH_SIZE_TEST)\n","iterator_test = batched_dataset_test.make_one_shot_iterator() \n","(batch_test_images, batch_test_labels) = iterator_test.get_next()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_PS2GjTxRZx9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# preprocess input for training and testing\n","def random_flip_left_right(image, flip_index, seed=None):\n","  shape = image.get_shape()\n","  if shape.ndims == 3 or shape.ndims is None:\n","    uniform_random = tf.random_uniform([], 0, 1.0, seed=seed)\n","    mirror_cond = tf.less(uniform_random, .5)\n","    result = tf.cond(\n","        mirror_cond,\n","        lambda: tf.reverse(image, [flip_index]),\n","        lambda: image\n","    )\n","    return fix_image_flip_shape(image, result)\n","  elif shape.ndims == 4:\n","    uniform_random = tf.random_uniform(\n","        [tf.shape(image)[0]], 0, 1.0, seed=seed\n","    )\n","    mirror_cond = tf.less(uniform_random, .5)\n","    return tf.where(\n","        mirror_cond,\n","        image,\n","        tf.map_fn(lambda x: tf.reverse(x, [flip_index]), image, dtype=image.dtype)\n","    )\n","  else:\n","    raise ValueError(\"\\'image\\' must have either 3 or 4 dimensions.\")\n","    \n","def train_image_preprocess(h, w, random_flip=True):\n","  \"\"\"Image processing required for training the model.\"\"\"\n","\n","  def fn(image):\n","    batch_size = image.get_shape().as_list()[0]\n","    # Ensure the data is in range [-1, 1].\n","    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n","    image = image * 2.0 - 1.0\n","    # Randomly choose a (24, 24, 3) patch to be used for training.\n","    image = tf.random_crop(image, size=(BATCH_SIZE_TRAIN, h, w, 3))\n","    # Randomly flip the image.\n","    image = random_flip_left_right(image, 2)\n","    return image\n","\n","  return fn\n","\n","def test_image_preprocess():\n","  def fn(image):\n","    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n","    image = image * 2.0 - 1.0\n","    return image\n","  return fn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gJnSIJ0EqDiu","colab_type":"text"},"cell_type":"markdown","source":["### Teacher model is baseline"]},{"metadata":{"id":"2scBoc09ZsO4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class Baseline(snt.AbstractModule):\n","  \n","  def __init__(self, num_classes, name=\"baseline\"):\n","    super(Baseline, self).__init__(name=name)\n","    self._num_classes = num_classes\n","    self._output_channels = [\n","        64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n","        ]\n","    self._num_layers = len(self._output_channels)\n","\n","    self._kernel_shapes = [[3, 3]] * self._num_layers  # All kernels are 3x3.\n","    self._strides = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n","    self._paddings = [snt.SAME] * self._num_layers\n","   \n","  def _build(self, inputs, is_training=None, test_local_stats=False):\n","    net = inputs\n","    # instantiate all the convolutional layers \n","    layers = [snt.Conv2D(name=\"conv_2d_{}\".format(i),\n","                         output_channels=self._output_channels[i],\n","                         kernel_shape=self._kernel_shapes[i],\n","                         stride=self._strides[i],\n","                         padding=self._paddings[i],\n","                         use_bias=True) for i in xrange(self._num_layers)]\n","    # connect them to the graph, adding batch norm and non-linearity\n","    for i, layer in enumerate(layers):\n","      net = layer(net)\n","      bn = snt.BatchNorm(name=\"batch_norm_{}\".format(i))\n","      net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n","      net = tf.nn.relu(net)\n","\n","    net = tf.reduce_mean(net, reduction_indices=[1, 2], keepdims=False,\n","                         name=\"avg_pool\")\n","\n","    logits = snt.Linear(self._num_classes)(net)\n","\n","    return logits"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CZm91aoqqIV7","colab_type":"text"},"cell_type":"markdown","source":["### Student model is Mobilenet"]},{"metadata":{"id":"vR3pnr5NVDwj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class Mobilenet(snt.AbstractModule):\n","  \n","  def __init__(self, num_classes, name=\"mobilenet\"):\n","    super(Mobilenet, self).__init__(name=name)\n","    self._num_classes = num_classes\n","    self._channel_multipliers = [\n","        0, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1\n","    ]\n","    self._output_channels = [\n","        64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n","    ]\n","    self._num_layers = len(self._output_channels)\n","\n","    self._kernel_shapes = [[3, 3]] * self._num_layers  # All kernels are 3x3.\n","    self._strides = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n","    self._paddings = [snt.SAME] * self._num_layers\n","   \n","  def _build(self, inputs, is_training=None, test_local_stats=False):\n","    net = inputs\n","    # instantiate all the convolutional layers\n","    first_conv = snt.Conv2D(name=\"conv_2d_0\",\n","                            output_channels=self._output_channels[0],\n","                            kernel_shape=self._kernel_shapes[0],\n","                            stride=self._strides[0],\n","                            padding=self._paddings[0],\n","                            use_bias=True)\n","    \n","    # instantiate depthwise conv layers\n","    conv_layers_dw = [snt.DepthwiseConv2D(name=\"conv_dw_2d_{}\".format(i),\n","                                          channel_multiplier=self._channel_multipliers[i],\n","                                          kernel_shape=self._kernel_shapes[i],\n","                                          stride=self._strides[i],\n","                                          padding=self._paddings[i],\n","                                          use_bias=True)\n","                      for i in xrange(1, self._num_layers)]\n","    \n","    # instantiate 1x1 conv layers\n","    conv_layers_1x1 = [snt.Conv2D(name=\"conv_1x1_2d_{}\".format(i),\n","                                  output_channels=self._output_channels[i],\n","                                  kernel_shape=(1, 1),\n","                                  stride=self._strides[i],\n","                                  padding=self._paddings[i],\n","                                  use_bias=True)\n","                       for i in xrange(1, self._num_layers)]\n","    # connect first layer to the graph, adding batch norm and non-linearity\n","    net = first_conv(net)\n","    bn = snt.BatchNorm(name=\"batch_norm_0\")\n","    net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n","    net = tf.nn.relu(net)\n","    \n","    # connect the rest of the layers\n","    for i, (layer_dw, layer_1x1) in enumerate(zip(conv_layers_dw, conv_layers_1x1)):\n","      net = layer_dw(net)\n","      bn = snt.BatchNorm(name=\"batch_norm_{}_0\".format(i))\n","      net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n","      net = tf.nn.relu(net)\n","      net = layer_1x1(net)\n","      bn = snt.BatchNorm(name=\"batch_norm_{}_1\".format(i))\n","      net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n","      net = tf.nn.relu(net)      \n","\n","    net = tf.reduce_mean(net, reduction_indices=[1, 2], keepdims=False,\n","                         name=\"avg_pool\")\n","\n","    logits = snt.Linear(self._num_classes)(net)\n","\n","    return logits"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TZzlpO0oJFZy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# First define the preprocessing ops for the train/test data\n","crop_height = 24 #@param\n","cropt_width = 24 #@param\n","preprocess_fn_train = train_image_preprocess(crop_height, cropt_width)\n","preprocess_fn_test = test_image_preprocess()\n","\n","num_classes = 10 #@param"],"execution_count":0,"outputs":[]},{"metadata":{"id":"698eQkBaVtNg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# for evaluation, we look at top_k_accuracy since it's easier to interpret; normally k=1 or k=5\n","def top_k_accuracy(k, labels, logits):\n","  in_top_k = tf.nn.in_top_k(predictions=tf.squeeze(logits), targets=tf.squeeze(tf.cast(labels, tf.int32)), k=k)\n","  return tf.reduce_mean(tf.cast(in_top_k, tf.float32))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6BoOamgZcFyA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Define number of training iterations and reporting intervals\n","TRAIN_ITERS = 90e3 #@param\n","REPORT_TRAIN_EVERY = 100 #@param\n","PLOT_EVERY = 500 #@param\n","REPORT_TEST_EVERY = 1000 #@param\n","TEST_ITERS = 10 #@param\n","lr_init = 0.01 #@param\n","display_inputs = False #@param\n","\n","class_mapping = [u'airplane', u'automobile', u'bird', u'cat', u'deer', u'dog', u'frog', u'horse', u'ship', u'truck']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0xI0ftMtqQjG","colab_type":"text"},"cell_type":"markdown","source":["### Instantiate teacher and load pre-trained weights\n"]},{"metadata":{"id":"V9eSqIp5WAKF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.variable_scope(\"teacher\"):\n","  teacher_model = Baseline(num_classes)\n","predictions_teacher = teacher_model(preprocess_fn_train(batch_train_images), is_training=False)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CtfBZ1_OO3L6","colab_type":"text"},"cell_type":"markdown","source":["We do not want to alter the teacher weights"]},{"metadata":{"id":"S0hD3ZL2O04r","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["predictions_teacher = tf.stop_gradient(predictions_teacher)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jtLgURi-O1gA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["var_list = snt.get_variables_in_scope(\"teacher\", collection=tf.GraphKeys.GLOBAL_VARIABLES)  \n","\n","var_map = {}\n","for i in range(0, len(var_list)):\n","  name = var_list[i].name[len(\"teacher/\"):-2]\n","  var_map[name] = var_list[i]\n","\n","saver = tf.train.Saver(var_map, reshape=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UhXzKr-TqlPx","colab_type":"text"},"cell_type":"markdown","source":["### Instantiate student"]},{"metadata":{"id":"g3S76cQUqksA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tf.variable_scope(\"student\"):\n","  student_model = Mobilenet(num_classes=num_classes)\n","# get predictions from the model\n","predictions_student = student_model(preprocess_fn_train(batch_train_images), is_training=True)\n","test_predictions_student = student_model(preprocess_fn_test(batch_test_images), is_training=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TnQvXQDEqqwy","colab_type":"text"},"cell_type":"markdown","source":["### For distillation, we use softmax with higher temperature. Normally T = 1; for distillation we use T>1.\n","\n","\\begin{equation}\n","q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}\n","\\end{equation}"]},{"metadata":{"id":"jzSh3XIDdNMC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# vizualise how the softmax temperature influences the output of the teacher\n","softmax_temp_distill = 5.0   # \n","softmax_temp_normal = 1.0 # \n","logits_high_temp = tf.nn.softmax(tf.div(predictions_teacher, softmax_temp_distill)) \n","logits_low_temp = tf.nn.softmax(tf.div(predictions_teacher, softmax_temp_normal))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TjgjChm_rAm2","colab_type":"text"},"cell_type":"markdown","source":["### Set up the training for Mobilenet, adding the distillation loss weighted by the square of temperature\n","- the gradient varies with the inverse of square of temperature"]},{"metadata":{"id":"vvnDmLsUc6JU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["lambda_ = softmax_temp_distill * softmax_temp_distill"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PzO_NMBKQL4Q","colab_type":"text"},"cell_type":"markdown","source":["**Define the classification loss**"]},{"metadata":{"id":"xc0TDWgUP-SO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","###################\n","#                 # \n","# YOUR CODE       #\n","# train_loss = ...# \n","#                 #\n","###################"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FRhpBqgOQPXa","colab_type":"text"},"cell_type":"markdown","source":["**Define the distillation loss**\n","\n","You may do this either with\n","\n","* `tf.distributions.kl_divergence` between distributions\n","* `softmax_cross_entropy_with_logits`. Remember that the labels are expected to sum to 1, while the output of the teacher network is logits."]},{"metadata":{"id":"ivYOPAmkQOBy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","########################\n","#                      # \n","# YOUR CODE            #\n","# distill_kl_loss = ...# \n","#                      #\n","########################"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nsfBoN1iQ8D3","colab_type":"text"},"cell_type":"markdown","source":["**Define the joint training loss**"]},{"metadata":{"id":"amN8bJDcQ6UQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","###################\n","#                 # \n","# YOUR CODE       #\n","# train_loss = ...# \n","#                 #\n","###################"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iMgsw2OASSpI","colab_type":"text"},"cell_type":"markdown","source":["### Create the training ops\n","\n","Make sure Batch Norm moving averages get updated - run UPDATE_OPS."]},{"metadata":{"id":"bg5vcWv1S6Ne","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_optimizer(step):\n","  \"\"\"Get the optimizer used for training.\"\"\"\n","  lr_schedule = (40e3, 60e3, 80e3)\n","  lr_schedule = tf.to_int64(lr_schedule)\n","  lr_factor = 0.1\n","  \n","  lr_init = 0.1\n","  num_epochs = tf.reduce_sum(tf.to_float(step >= lr_schedule))\n","  lr = lr_init * lr_factor**num_epochs\n","\n","  return tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FA04yKaoS-qt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Create a global step that is incremented during training; useful for e.g. learning rate annealing\n","global_step = tf.train.get_or_create_global_step()\n","\n","# instantiate the optimizer\n","optimizer = get_optimizer(global_step)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gyuKGA1ZSQvC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Get training and test ops\n","training_op = optimizer.minimize(train_loss, global_step)\n","update_ops = tf.group(*tf.get_collection(tf.GraphKeys.UPDATE_OPS))\n","training_op = tf.group(training_op, update_ops)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BLzmNbeLSdgf","colab_type":"text"},"cell_type":"markdown","source":["### Teacher and student accuracy"]},{"metadata":{"id":"JbHwP67QSaGh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_acc = top_k_accuracy(1, batch_test_labels, test_predictions_student)\n","acc_teacher = top_k_accuracy(1, batch_train_labels, predictions_teacher) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"M6ajGgfzcdh3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Create the session and initialize variables\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q8DKMYb3rIg3","colab_type":"text"},"cell_type":"markdown","source":["### Load pre-trained weights for teacher, and check accuracy to make sure the import was successful"]},{"metadata":{"id":"LUUJ84-QbyOA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":930},"outputId":"e1087314-f331-4b18-b2e3-5bec60f8268f","executionInfo":{"status":"error","timestamp":1531832217288,"user_tz":-60,"elapsed":10698,"user":{"displayName":"Mihaela Rosca","photoUrl":"//lh5.googleusercontent.com/-q8OFNZCyEkk/AAAAAAAAAAI/AAAAAAAABJg/Qg8HHX2XAI0/s50-c-k-no/photo.jpg","userId":"107992561331291226743"}}},"cell_type":"code","source":["saver.restore(sess, \"baseline.ckpt\")\n"," \n","test_batch_size = 100\n","num_batches = 100  # 100 batches * 100 samples per batch = 10000\n","\n","avg_accuracy = 0.\n","\n","###################\n","#                 # \n","# YOUR CODE       #\n","#                 #\n","###################\n","\n","# Check if import was done correctly by running eval on cifar train set\n","# expected_accuracy ~ 0.94\n","print (\"Teacher accuracy {:.3f}\".format(avg_accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from baseline.ckpt\n"],"name":"stdout"},{"output_type":"error","ename":"InternalError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-31-786808dd87e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m  \u001b[0;31m# 100 batches * 100 samples per batch = 10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mavg_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1750\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1752\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1753\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m       \u001b[0mexception_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: save/RestoreV2/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_221_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]"]}]},{"metadata":{"id":"sIK7-OSdSkVY","colab_type":"text"},"cell_type":"markdown","source":["### Visualize the impact of temperature on the logits"]},{"metadata":{"id":"6GHU1c6bs6ir","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["logits_ht, logits_lt, gt = sess.run([logits_high_temp, logits_low_temp, tf.one_hot(batch_train_labels, num_classes)])\n","# pick one sample and plot\n","idx = 33\n","plt.plot(logits_ht[idx], c='r', label='High Temp')\n","plt.plot(logits_lt[idx], c='g', label='Low Temp')\n","plt.plot(gt[idx,0], 'b--', label='GT')\n","plt.xlim([0,9])\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pM9cnYRATPdw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Write a function that takes a list of losses and plots them.\n","def plot_losses(loss_list, steps):\n","  display.clear_output(wait=True)\n","  display.display(pl.gcf())\n","  pl.plot(steps, loss_list, c='b')\n","  time.sleep(1.0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QHE75BhpSoVk","colab_type":"text"},"cell_type":"markdown","source":["### Train the model"]},{"metadata":{"id":"C2877dV3Sxxr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_iter = 0\n","losses = []\n","steps = []\n","for train_iter in range(int(TRAIN_ITERS)):\n","  _, train_loss_np = sess.run([training_op, train_loss])\n","  \n","  if (train_iter % REPORT_TRAIN_EVERY) == 0:\n","    losses.append(train_loss_np)\n","    steps.append(train_iter)\n","  if (train_iter % PLOT_EVERY) == 0:\n","    plot_losses(losses, steps)    \n","    \n","  if (train_iter % REPORT_TEST_EVERY) == 0:\n","    avg_acc = 0.0\n","    for test_iter in range(TEST_ITERS):\n","      acc = sess.run(test_acc)\n","      avg_acc += acc\n","      \n","    avg_acc /= (TEST_ITERS)\n","    print ('Test acc at iter {0:5d} out of {1:5d} is {2:.2f}%'.format(int(train_iter), int(TRAIN_ITERS), avg_acc*100.0))"],"execution_count":0,"outputs":[]}]}